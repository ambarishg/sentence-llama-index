{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index\n",
      "  Using cached llama_index-0.10.14-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting llama-index-agent-openai<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Using cached llama_index_agent_openai-0.1.5-py3-none-any.whl.metadata (695 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Using cached llama_index_cli-0.1.6-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.14 (from llama-index)\n",
      "  Downloading llama_index_core-0.10.14.post1-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Using cached llama_index_embeddings_openai-0.1.6-py3-none-any.whl.metadata (654 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Using cached llama_index_indices_managed_llama_cloud-0.1.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index)\n",
      "  Using cached llama_index_legacy-0.9.48-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.5 (from llama-index)\n",
      "  Downloading llama_index_llms_openai-0.1.7-py3-none-any.whl.metadata (557 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Using cached llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index)\n",
      "  Using cached llama_index_program_openai-0.1.4-py3-none-any.whl.metadata (766 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index)\n",
      "  Using cached llama_index_readers_file-0.1.6-py3-none-any.whl.metadata (977 bytes)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index)\n",
      "  Using cached llama_index_readers_llama_parse-0.1.3-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting llama-index-vector-stores-chroma<0.2.0,>=0.1.1 (from llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached llama_index_vector_stores_chroma-0.1.5-py3-none-any.whl.metadata (795 bytes)\n",
      "Collecting PyYAML>=6.0.1 (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy>=1.4.49 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached SQLAlchemy-2.0.27-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.6 (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting dataclasses-json (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached dataclasses_json-0.6.4-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.13 (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached llamaindex_py_client-0.1.13-py3-none-any.whl.metadata (762 bytes)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.14->llama-index) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached networkx-3.2.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting nltk<4.0.0,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting numpy (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting openai>=1.1.0 (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached openai-1.13.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pandas (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting pillow>=9.0.0 (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Collecting requests>=2.31.0 (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity<9.0.0,>=8.2.0 (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting tqdm<5.0.0,>=4.66.1 (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached typing_extensions-4.10.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting typing-inspect>=0.8.0 (from llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bs4<0.0.3,>=0.0.2 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Using cached bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n",
      "Collecting pymupdf<2.0.0,>=1.23.21 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Downloading PyMuPDF-1.23.26-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Using cached pypdf-4.0.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting llama-parse<0.4.0,>=0.3.3 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached llama_parse-0.3.5-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Using cached soupsieve-2.5-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting wrapt<2,>=1.10 (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting chromadb<0.5.0,>=0.4.22 (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting onnxruntime<2.0.0,>=1.17.0 (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting tokenizers<0.16.0,>=0.15.1 (from llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting pydantic>=1.10 (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
      "Collecting anyio (from httpx->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached anyio-4.3.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting certifi (from httpx->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting httpcore==1.* (from httpx->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached httpcore-1.0.4-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting idna (from httpx->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting sniffio (from httpx->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting click (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting PyMuPDFb==1.23.22 (from pymupdf<2.0.0,>=1.23.21->llama-index-readers-file<0.2.0,>=0.1.4->llama-index)\n",
      "  Using cached PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached marshmallow-3.21.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.14->llama-index) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.14->llama-index) (1.2.0)\n",
      "Collecting build>=1.0.3 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading build-1.1.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached fastapi-0.110.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached uvicorn-0.27.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting posthog>=2.4.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached posthog-3.4.2-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached opentelemetry_api-1.23.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached opentelemetry_sdk-1.23.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
      "Collecting overrides>=7.3.1 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached importlib_resources-6.1.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached grpcio-1.62.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached typer-0.9.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mmh3>=4.0.1 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Collecting orjson>=3.9.12 (from chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.14->llama-index) (23.2)\n",
      "Collecting coloredlogs (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting protobuf (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting sympy (from onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached sympy-1.12-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.16.3 (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.14->llama-index)\n",
      "  Using cached pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.14->llama-index) (1.16.0)\n",
      "Collecting huggingface_hub<1.0,>=0.16.4 (from tokenizers<0.16.0,>=0.15.1->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Downloading huggingface_hub-0.21.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached pyproject_hooks-1.0.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tomli>=1.1.0 (from build>=1.0.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached tomli-2.0.1-py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting starlette<0.37.0,>=0.36.3 (from fastapi>=0.95.2->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached starlette-0.36.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting filelock (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.1->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached filelock-3.13.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached google_auth-2.28.1-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached websocket_client-1.7.0-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached googleapis_common_protos-1.62.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.23.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached opentelemetry_proto-1.23.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached opentelemetry_instrumentation-0.44b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached opentelemetry_util_http-0.44b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting setuptools>=16.0 (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached setuptools-69.1.1-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached asgiref-3.7.2-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath>=0.19 (from sympy->onnxruntime<2.0.0,>=1.17.0->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached zipp-3.17.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb<0.5.0,>=0.4.22->llama-index-vector-stores-chroma<0.2.0,>=0.1.1->llama-index-cli<0.2.0,>=0.1.2->llama-index)\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached llama_index-0.10.14-py3-none-any.whl (5.6 kB)\n",
      "Using cached llama_index_agent_openai-0.1.5-py3-none-any.whl (12 kB)\n",
      "Using cached llama_index_cli-0.1.6-py3-none-any.whl (25 kB)\n",
      "Downloading llama_index_core-0.10.14.post1-py3-none-any.whl (15.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached llama_index_embeddings_openai-0.1.6-py3-none-any.whl (6.0 kB)\n",
      "Using cached llama_index_indices_managed_llama_cloud-0.1.3-py3-none-any.whl (6.6 kB)\n",
      "Using cached llama_index_legacy-0.9.48-py3-none-any.whl (2.0 MB)\n",
      "Downloading llama_index_llms_openai-0.1.7-py3-none-any.whl (9.3 kB)\n",
      "Using cached llama_index_multi_modal_llms_openai-0.1.4-py3-none-any.whl (5.8 kB)\n",
      "Using cached llama_index_program_openai-0.1.4-py3-none-any.whl (4.1 kB)\n",
      "Using cached llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Using cached llama_index_readers_file-0.1.6-py3-none-any.whl (34 kB)\n",
      "Using cached llama_index_readers_llama_parse-0.1.3-py3-none-any.whl (2.5 kB)\n",
      "Using cached aiohttp-3.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Using cached bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n",
      "Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Using cached fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "Using cached llama_index_vector_stores_chroma-0.1.5-py3-none-any.whl (4.7 kB)\n",
      "Using cached llama_parse-0.3.5-py3-none-any.whl (7.7 kB)\n",
      "Using cached llamaindex_py_client-0.1.13-py3-none-any.whl (107 kB)\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
      "Using cached networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached openai-1.13.3-py3-none-any.whl (227 kB)\n",
      "Using cached pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "Downloading PyMuPDF-1.23.26-cp310-none-manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached PyMuPDFb-1.23.22-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (30.6 MB)\n",
      "Using cached pypdf-4.0.2-py3-none-any.whl (283 kB)\n",
      "Using cached PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached SQLAlchemy-2.0.27-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Using cached tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Using cached tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
      "Using cached tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "Using cached typing_extensions-4.10.0-py3-none-any.whl (33 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Using cached numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Using cached pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached anyio-4.3.0-py3-none-any.whl (85 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Using cached chromadb-0.4.24-py3-none-any.whl (525 kB)\n",
      "Using cached chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "Using cached greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Using cached marshmallow-3.21.0-py3-none-any.whl (49 kB)\n",
      "Using cached multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "Using cached pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
      "Using cached pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached regex-2023.12.25-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached soupsieve-2.5-py3-none-any.whl (36 kB)\n",
      "Using cached tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Using cached wrapt-1.16.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (80 kB)\n",
      "Using cached yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Using cached annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Using cached bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
      "Downloading build-1.1.1-py3-none-any.whl (19 kB)\n",
      "Using cached fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
      "Using cached grpcio-1.62.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.5 MB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading huggingface_hub-0.21.3-py3-none-any.whl (346 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.2/346.2 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Using cached mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "Using cached opentelemetry_api-1.23.0-py3-none-any.whl (58 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_grpc-1.23.0-py3-none-any.whl (18 kB)\n",
      "Using cached opentelemetry_exporter_otlp_proto_common-1.23.0-py3-none-any.whl (17 kB)\n",
      "Using cached opentelemetry_proto-1.23.0-py3-none-any.whl (50 kB)\n",
      "Using cached opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl (11 kB)\n",
      "Using cached opentelemetry_instrumentation-0.44b0-py3-none-any.whl (28 kB)\n",
      "Using cached opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl (14 kB)\n",
      "Using cached opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl (36 kB)\n",
      "Using cached opentelemetry_util_http-0.44b0-py3-none-any.whl (6.9 kB)\n",
      "Using cached opentelemetry_sdk-1.23.0-py3-none-any.whl (105 kB)\n",
      "Using cached orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached posthog-3.4.2-py2.py3-none-any.whl (41 kB)\n",
      "Using cached protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Using cached pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "Using cached typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "Using cached uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Using cached importlib_resources-6.1.2-py3-none-any.whl (34 kB)\n",
      "Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Using cached google_auth-2.28.1-py2.py3-none-any.whl (186 kB)\n",
      "Using cached googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
      "Using cached httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Using cached starlette-0.36.3-py3-none-any.whl (71 kB)\n",
      "Using cached tomli-2.0.1-py3-none-any.whl (12 kB)\n",
      "Using cached uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "Using cached watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Using cached websocket_client-1.7.0-py3-none-any.whl (58 kB)\n",
      "Using cached websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "Using cached filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Using cached pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\n",
      "Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Using cached asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
      "Using cached cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached setuptools-69.1.1-py3-none-any.whl (819 kB)\n",
      "Using cached zipp-3.17.0-py3-none-any.whl (7.4 kB)\n",
      "Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Installing collected packages: pytz, pypika, mpmath, monotonic, mmh3, flatbuffers, dirtyjson, zipp, wrapt, websockets, websocket-client, uvloop, urllib3, tzdata, typing-extensions, tqdm, tomli, tenacity, sympy, soupsieve, sniffio, setuptools, regex, PyYAML, python-dotenv, pypdf, PyMuPDFb, pyasn1, protobuf, pillow, overrides, orjson, opentelemetry-util-http, opentelemetry-semantic-conventions, oauthlib, numpy, networkx, mypy-extensions, multidict, marshmallow, joblib, importlib-resources, idna, humanfriendly, httptools, h11, grpcio, greenlet, fsspec, frozenlist, filelock, distro, click, charset-normalizer, certifi, cachetools, bcrypt, backoff, attrs, async-timeout, annotated-types, yarl, uvicorn, typing-inspect, typer, SQLAlchemy, rsa, requests, pyproject_hooks, pymupdf, pydantic-core, pyasn1-modules, pulsar-client, pandas, opentelemetry-proto, nltk, importlib-metadata, httpcore, googleapis-common-protos, deprecated, coloredlogs, chroma-hnswlib, beautifulsoup4, asgiref, anyio, aiosignal, watchfiles, tiktoken, starlette, requests-oauthlib, pydantic, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, huggingface_hub, httpx, google-auth, dataclasses-json, build, bs4, aiohttp, tokenizers, opentelemetry-sdk, opentelemetry-instrumentation, openai, llamaindex-py-client, kubernetes, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, llama-index-legacy, llama-index-core, opentelemetry-instrumentation-fastapi, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-agent-openai, chromadb, llama-index-vector-stores-chroma, llama-index-program-openai, llama-index-question-gen-openai, llama-index-cli, llama-index\n",
      "Successfully installed PyMuPDFb-1.23.22 PyYAML-6.0.1 SQLAlchemy-2.0.27 aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 anyio-4.3.0 asgiref-3.7.2 async-timeout-4.0.3 attrs-23.2.0 backoff-2.2.1 bcrypt-4.1.2 beautifulsoup4-4.12.3 bs4-0.0.2 build-1.1.1 cachetools-5.3.3 certifi-2024.2.2 charset-normalizer-3.3.2 chroma-hnswlib-0.7.3 chromadb-0.4.24 click-8.1.7 coloredlogs-15.0.1 dataclasses-json-0.6.4 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 fastapi-0.110.0 filelock-3.13.1 flatbuffers-23.5.26 frozenlist-1.4.1 fsspec-2024.2.0 google-auth-2.28.1 googleapis-common-protos-1.62.0 greenlet-3.0.3 grpcio-1.62.0 h11-0.14.0 httpcore-1.0.4 httptools-0.6.1 httpx-0.27.0 huggingface_hub-0.21.3 humanfriendly-10.0 idna-3.6 importlib-metadata-6.11.0 importlib-resources-6.1.2 joblib-1.3.2 kubernetes-29.0.0 llama-index-0.10.14 llama-index-agent-openai-0.1.5 llama-index-cli-0.1.6 llama-index-core-0.10.14.post1 llama-index-embeddings-openai-0.1.6 llama-index-indices-managed-llama-cloud-0.1.3 llama-index-legacy-0.9.48 llama-index-llms-openai-0.1.7 llama-index-multi-modal-llms-openai-0.1.4 llama-index-program-openai-0.1.4 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.6 llama-index-readers-llama-parse-0.1.3 llama-index-vector-stores-chroma-0.1.5 llama-parse-0.3.5 llamaindex-py-client-0.1.13 marshmallow-3.21.0 mmh3-4.1.0 monotonic-1.6 mpmath-1.3.0 multidict-6.0.5 mypy-extensions-1.0.0 networkx-3.2.1 nltk-3.8.1 numpy-1.26.4 oauthlib-3.2.2 onnxruntime-1.17.1 openai-1.13.3 opentelemetry-api-1.23.0 opentelemetry-exporter-otlp-proto-common-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.23.0 opentelemetry-instrumentation-0.44b0 opentelemetry-instrumentation-asgi-0.44b0 opentelemetry-instrumentation-fastapi-0.44b0 opentelemetry-proto-1.23.0 opentelemetry-sdk-1.23.0 opentelemetry-semantic-conventions-0.44b0 opentelemetry-util-http-0.44b0 orjson-3.9.15 overrides-7.7.0 pandas-2.2.1 pillow-10.2.0 posthog-3.4.2 protobuf-4.25.3 pulsar-client-3.4.0 pyasn1-0.5.1 pyasn1-modules-0.3.0 pydantic-2.6.3 pydantic-core-2.16.3 pymupdf-1.23.26 pypdf-4.0.2 pypika-0.48.9 pyproject_hooks-1.0.0 python-dotenv-1.0.1 pytz-2024.1 regex-2023.12.25 requests-2.31.0 requests-oauthlib-1.3.1 rsa-4.9 setuptools-69.1.1 sniffio-1.3.1 soupsieve-2.5 starlette-0.36.3 sympy-1.12 tenacity-8.2.3 tiktoken-0.6.0 tokenizers-0.15.2 tomli-2.0.1 tqdm-4.66.2 typer-0.9.0 typing-extensions-4.10.0 typing-inspect-0.9.0 tzdata-2024.1 urllib3-2.2.1 uvicorn-0.27.1 uvloop-0.19.0 watchfiles-0.21.0 websocket-client-1.7.0 websockets-12.0 wrapt-1.16.0 yarl-1.9.4 zipp-3.17.0\n"
     ]
    }
   ],
   "source": [
    "! pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.10/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-llms-azure-openai\n",
      "  Using cached llama_index_llms_azure_openai-0.1.5-py3-none-any.whl.metadata (786 bytes)\n",
      "Collecting azure-identity<2.0.0,>=1.15.0 (from llama-index-llms-azure-openai)\n",
      "  Using cached azure_identity-1.15.0-py3-none-any.whl.metadata (75 kB)\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.10/site-packages (from llama-index-llms-azure-openai) (0.27.0)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.11.post1 in ./.venv/lib/python3.10/site-packages (from llama-index-llms-azure-openai) (0.10.14.post1)\n",
      "Requirement already satisfied: llama-index-llms-openai<0.2.0,>=0.1.1 in ./.venv/lib/python3.10/site-packages (from llama-index-llms-azure-openai) (0.1.7)\n",
      "Collecting azure-core<2.0.0,>=1.23.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai)\n",
      "  Downloading azure_core-1.30.1-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting cryptography>=2.5 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai)\n",
      "  Using cached cryptography-42.0.5-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting msal<2.0.0,>=1.24.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai)\n",
      "  Using cached msal-1.27.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions<2.0.0,>=0.3.0 (from azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai)\n",
      "  Using cached msal_extensions-1.1.0-py3-none-any.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (2024.2.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (3.8.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (1.13.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (0.9.0)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-llms-azure-openai) (4.3.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-llms-azure-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-llms-azure-openai) (1.0.4)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-llms-azure-openai) (3.6)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-llms-azure-openai) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-llms-azure-openai) (0.14.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (4.0.3)\n",
      "Requirement already satisfied: six>=1.11.0 in ./.venv/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.23.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (1.16.0)\n",
      "Collecting cffi>=1.12 (from cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai)\n",
      "  Using cached cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.10/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (1.16.0)\n",
      "Requirement already satisfied: pydantic>=1.10 in ./.venv/lib/python3.10/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (2.6.3)\n",
      "Collecting PyJWT<3,>=1.0.0 (from PyJWT[crypto]<3,>=1.0.0->msal<2.0.0,>=1.24.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai)\n",
      "  Using cached PyJWT-2.8.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.10/site-packages (from msal-extensions<2.0.0,>=0.3.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai) (23.2)\n",
      "Collecting portalocker<3,>=1.0 (from msal-extensions<2.0.0,>=0.3.0->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai)\n",
      "  Using cached portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (1.9.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio->httpx->llama-index-llms-azure-openai) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (3.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (2024.1)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0.0,>=1.15.0->llama-index-llms-azure-openai)\n",
      "  Using cached pycparser-2.21-py2.py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in ./.venv/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-llms-azure-openai) (2.16.3)\n",
      "Using cached llama_index_llms_azure_openai-0.1.5-py3-none-any.whl (4.5 kB)\n",
      "Using cached azure_identity-1.15.0-py3-none-any.whl (164 kB)\n",
      "Downloading azure_core-1.30.1-py3-none-any.whl (193 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.4/193.4 kB\u001b[0m \u001b[31m260.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached cryptography-42.0.5-cp39-abi3-manylinux_2_28_x86_64.whl (4.6 MB)\n",
      "Using cached msal-1.27.0-py2.py3-none-any.whl (101 kB)\n",
      "Using cached msal_extensions-1.1.0-py3-none-any.whl (19 kB)\n",
      "Using cached cffi-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
      "Using cached portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
      "Using cached PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
      "Using cached pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
      "Installing collected packages: PyJWT, pycparser, portalocker, cffi, azure-core, cryptography, msal, msal-extensions, azure-identity, llama-index-llms-azure-openai\n",
      "Successfully installed PyJWT-2.8.0 azure-core-1.30.1 azure-identity-1.15.0 cffi-1.16.0 cryptography-42.0.5 llama-index-llms-azure-openai-0.1.5 msal-1.27.0 msal-extensions-1.1.0 portalocker-2.8.2 pycparser-2.21\n"
     ]
    }
   ],
   "source": [
    "! pip install llama-index-llms-azure-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting qdrant-client\n",
      "  Using cached qdrant_client-1.7.3-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: grpcio>=1.41.0 in ./.venv/lib/python3.10/site-packages (from qdrant-client) (1.62.0)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client)\n",
      "  Using cached grpcio_tools-1.62.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: httpx>=0.14.0 in ./.venv/lib/python3.10/site-packages (from httpx[http2]>=0.14.0->qdrant-client) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.21 in ./.venv/lib/python3.10/site-packages (from qdrant-client) (1.26.4)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in ./.venv/lib/python3.10/site-packages (from qdrant-client) (2.8.2)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in ./.venv/lib/python3.10/site-packages (from qdrant-client) (2.6.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in ./.venv/lib/python3.10/site-packages (from qdrant-client) (2.2.1)\n",
      "Requirement already satisfied: protobuf<5.0dev,>=4.21.6 in ./.venv/lib/python3.10/site-packages (from grpcio-tools>=1.41.0->qdrant-client) (4.25.3)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from grpcio-tools>=1.41.0->qdrant-client) (69.1.1)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.10/site-packages (from httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant-client) (4.3.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant-client) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant-client) (1.0.4)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.10/site-packages (from httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant-client) (3.6)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant-client) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant-client) (0.14.0)\n",
      "Collecting h2<5,>=3 (from httpx[http2]>=0.14.0->qdrant-client)\n",
      "  Using cached h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic>=1.10.8->qdrant-client) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in ./.venv/lib/python3.10/site-packages (from pydantic>=1.10.8->qdrant-client) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in ./.venv/lib/python3.10/site-packages (from pydantic>=1.10.8->qdrant-client) (4.10.0)\n",
      "Collecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant-client)\n",
      "  Using cached hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant-client)\n",
      "  Using cached hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio->httpx>=0.14.0->httpx[http2]>=0.14.0->qdrant-client) (1.2.0)\n",
      "Using cached qdrant_client-1.7.3-py3-none-any.whl (206 kB)\n",
      "Using cached grpcio_tools-1.62.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "Using cached h2-4.1.0-py3-none-any.whl (57 kB)\n",
      "Using cached hpack-4.0.0-py3-none-any.whl (32 kB)\n",
      "Using cached hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: hyperframe, hpack, grpcio-tools, h2, qdrant-client\n",
      "Successfully installed grpcio-tools-1.62.0 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 qdrant-client-1.7.3\n"
     ]
    }
   ],
   "source": [
    "! pip install qdrant-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-vector-stores-qdrant\n",
      "  Using cached llama_index_vector_stores_qdrant-0.1.3-py3-none-any.whl.metadata (749 bytes)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.60.0 in ./.venv/lib/python3.10/site-packages (from llama-index-vector-stores-qdrant) (1.62.0)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in ./.venv/lib/python3.10/site-packages (from llama-index-vector-stores-qdrant) (0.10.14.post1)\n",
      "Requirement already satisfied: qdrant-client<2.0.0,>=1.7.1 in ./.venv/lib/python3.10/site-packages (from llama-index-vector-stores-qdrant) (1.7.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2024.2.0)\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.8.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.13.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (10.2.0)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.9.0)\n",
      "Requirement already satisfied: grpcio-tools>=1.41.0 in ./.venv/lib/python3.10/site-packages (from qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant) (1.62.0)\n",
      "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in ./.venv/lib/python3.10/site-packages (from qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant) (2.8.2)\n",
      "Requirement already satisfied: pydantic>=1.10.8 in ./.venv/lib/python3.10/site-packages (from qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant) (2.6.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.14 in ./.venv/lib/python3.10/site-packages (from qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant) (2.2.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (4.0.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.10/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.16.0)\n",
      "Requirement already satisfied: protobuf<5.0dev,>=4.21.6 in ./.venv/lib/python3.10/site-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant) (4.25.3)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (from grpcio-tools>=1.41.0->qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant) (69.1.1)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (4.3.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.0.4)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.6)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (0.14.0)\n",
      "Requirement already satisfied: h2<5,>=3 in ./.venv/lib/python3.10/site-packages (from httpx[http2]>=0.14.0->qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant) (4.1.0)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2023.12.25)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic>=1.10.8->qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in ./.venv/lib/python3.10/site-packages (from pydantic>=1.10.8->qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.3.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (3.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.2.0)\n",
      "Requirement already satisfied: hyperframe<7,>=6.0 in ./.venv/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant) (6.0.1)\n",
      "Requirement already satisfied: hpack<5,>=4.0 in ./.venv/lib/python3.10/site-packages (from h2<5,>=3->httpx[http2]>=0.14.0->qdrant-client<2.0.0,>=1.7.1->llama-index-vector-stores-qdrant) (4.0.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./.venv/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (23.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-vector-stores-qdrant) (1.16.0)\n",
      "Using cached llama_index_vector_stores_qdrant-0.1.3-py3-none-any.whl (8.6 kB)\n",
      "Installing collected packages: llama-index-vector-stores-qdrant\n",
      "Successfully installed llama-index-vector-stores-qdrant-0.1.3\n"
     ]
    }
   ],
   "source": [
    "! pip install llama-index-vector-stores-qdrant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install llama-index-embeddings-huggingface --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-index-embeddings-fastembed\n",
      "  Using cached llama_index_embeddings_fastembed-0.1.4-py3-none-any.whl.metadata (662 bytes)\n",
      "Collecting fastembed<0.3.0,>=0.2.2 (from llama-index-embeddings-fastembed)\n",
      "  Using cached fastembed-0.2.2-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.11.post1 in ./.venv/lib/python3.10/site-packages (from llama-index-embeddings-fastembed) (0.10.14.post1)\n",
      "Collecting huggingface-hub<0.21,>=0.20 (from fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed)\n",
      "  Using cached huggingface_hub-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting loguru<0.8.0,>=0.7.2 (from fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed)\n",
      "  Using cached loguru-0.7.2-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in ./.venv/lib/python3.10/site-packages (from fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (1.26.4)\n",
      "Collecting onnx<2.0.0,>=1.15.0 (from fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed)\n",
      "  Using cached onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
      "Requirement already satisfied: onnxruntime<2.0.0,>=1.17.0 in ./.venv/lib/python3.10/site-packages (from fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (1.17.1)\n",
      "Requirement already satisfied: requests<3.0,>=2.31 in ./.venv/lib/python3.10/site-packages (from fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.16.0,>=0.15.1 in ./.venv/lib/python3.10/site-packages (from fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0,>=4.66 in ./.venv/lib/python3.10/site-packages (from fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (4.66.2)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2.0.27)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (0.6.4)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2024.2.0)\n",
      "Requirement already satisfied: httpx in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (0.27.0)\n",
      "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.13 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (0.1.13)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (3.2.1)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (3.8.1)\n",
      "Requirement already satisfied: openai>=1.1.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.13.3)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (10.2.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (8.2.3)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (0.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (4.10.0)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./.venv/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (0.9.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (4.0.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.10/site-packages (from deprecated>=1.2.9.3->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.16.0)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from huggingface-hub<0.21,>=0.20->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (3.13.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<0.21,>=0.20->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (23.2)\n",
      "Requirement already satisfied: pydantic>=1.10 in ./.venv/lib/python3.10/site-packages (from llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2.6.3)\n",
      "Requirement already satisfied: anyio in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (4.3.0)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.0.4)\n",
      "Requirement already satisfied: idna in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (3.6)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (0.14.0)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./.venv/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2023.12.25)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in ./.venv/lib/python3.10/site-packages (from onnx<2.0.0,>=1.15.0->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (4.25.3)\n",
      "Requirement already satisfied: coloredlogs in ./.venv/lib/python3.10/site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in ./.venv/lib/python3.10/site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (23.5.26)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (1.12)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3.0,>=2.31->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3.0,>=2.31->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (2.2.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.10/site-packages (from SQLAlchemy>=1.4.49->SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (3.0.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (3.21.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2024.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in ./.venv/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.13->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (2.16.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.11.post1->llama-index-embeddings-fastembed) (1.16.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./.venv/lib/python3.10/site-packages (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.10/site-packages (from sympy->onnxruntime<2.0.0,>=1.17.0->fastembed<0.3.0,>=0.2.2->llama-index-embeddings-fastembed) (1.3.0)\n",
      "Using cached llama_index_embeddings_fastembed-0.1.4-py3-none-any.whl (2.7 kB)\n",
      "Using cached fastembed-0.2.2-py3-none-any.whl (22 kB)\n",
      "Using cached huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
      "Using cached loguru-0.7.2-py3-none-any.whl (62 kB)\n",
      "Using cached onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
      "Installing collected packages: onnx, loguru, huggingface-hub, fastembed, llama-index-embeddings-fastembed\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.21.3\n",
      "    Uninstalling huggingface-hub-0.21.3:\n",
      "      Successfully uninstalled huggingface-hub-0.21.3\n",
      "Successfully installed fastembed-0.2.2 huggingface-hub-0.20.3 llama-index-embeddings-fastembed-0.1.4 loguru-0.7.2 onnx-1.15.0\n"
     ]
    }
   ],
   "source": [
    "! pip install llama-index-embeddings-fastembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
